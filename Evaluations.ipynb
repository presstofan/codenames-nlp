{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from itertools import compress\n",
    "from scipy import spatial\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_glove = pickle.load(open(\"glove_6B_300d_lite.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_bert = pickle.load(open(\"bert_uncased_L-12_H-768_A-12_lite.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Codenames word list\n",
    "codenames_df = pd.read_csv(\"word_list/codenames_word_list.csv\") \n",
    "codenames = pd.melt(codenames_df, id_vars=['ID', 'Version'], value_vars=['SideA', 'SideB'],\n",
    "        var_name='Side', value_name='Codename')['Codename'].tolist()\n",
    "codenames = [i.lower() for i in codenames] # convert to lowercase\n",
    "\n",
    "# Remove two-word nouns\n",
    "one_word_idx = [' ' not in i for i in codenames]\n",
    "codenames = [i for (i, v) in zip(codenames, one_word_idx) if v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    \n",
    "    def __init__(self, word_list, seed):\n",
    "        # Initialise random number generator\n",
    "        self.generator = np.random.RandomState(seed=seed)\n",
    "        # Set board size (use the 5 x 5 setup)\n",
    "        size = 5\n",
    "        self.words = np.array(word_list)\n",
    "        # Shuffle the wordlist\n",
    "        shuffle = self.generator.choice(\n",
    "            len(self.words), size * size, replace=False)\n",
    "        self.board = self.words[shuffle]\n",
    "        # Specify the layout for this game\n",
    "        assignments = self.generator.permutation(size * size)\n",
    "        self.owner = np.empty(size * size, int)\n",
    "        self.owner[assignments[0]] = 0  # assassin\n",
    "        self.owner[assignments[1:10]] = 1  # first player: 9 words\n",
    "        self.owner[assignments[10:18]] = 2  # second player: 8 words\n",
    "        self.owner[assignments[18:]] = 3  # bystander: 7 words\n",
    "        self.assassin_word = self.board[self.owner == 0].tolist()\n",
    "        self.team1_word = self.board[self.owner == 1].tolist()\n",
    "        self.team2_word = self.board[self.owner == 2].tolist()\n",
    "        self.bystander_word = self.board[self.owner == 3].tolist()\n",
    "        \n",
    "    def print_words(self):\n",
    "        print(\"Team 1: \")\n",
    "        print(self.team1_word)\n",
    "        print(\"Team 2: \")\n",
    "        print(self.team2_word)\n",
    "        print(\"Assassin: \")\n",
    "        print(self.assassin_word)\n",
    "        print(\"Bystanders: \")\n",
    "        print(self.bystander_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "game1 = Game(codenames, 53321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team 1: \n",
      "['keg', 'hercules', 'shampoo', 'sloth', 'mole', 'hawaii', 'comb', 'leather', 'egypt']\n",
      "Team 2: \n",
      "['tokyo', 'rug', 'post', 'novel', 'chick', 'safe', 'spider', 'champagne']\n",
      "Assassin: \n",
      "['bulb']\n",
      "Bystanders: \n",
      "['fan', 'oil', 'cook', 'manboobs', 'cowgirl', 'strip', 'queer']\n"
     ]
    }
   ],
   "source": [
    "game1.print_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpyMaster:\n",
    "    \n",
    "    def __init__(self, embeddings, game):\n",
    "        self.embeddings = embeddings\n",
    "        self.game = game\n",
    "        self.answers = game.team1_word\n",
    "        self.bad = game.team2_word + game.assassin_word\n",
    "    \n",
    "    def distance(self, word, reference):\n",
    "        return spatial.distance.cosine(self.embeddings[word], self.embeddings[reference])\n",
    "\n",
    "    def closest_words(self, reference):\n",
    "        return sorted(self.embeddings.keys(), key=lambda w: self.distance(w, reference))\n",
    "\n",
    "    def goodness(self, word, answers, bad):\n",
    "        if word in self.answers + self.bad: return -999\n",
    "        return sum([self.distance(word, b) for b in bad]) - 4.0 * sum([self.distance(word, a) for a in answers])\n",
    "\n",
    "    def minimax(self, word, answers, bad):\n",
    "        if word in answers + bad: return -999\n",
    "        return min([self.distance(word, b) for b in bad]) - max([self.distance(word, a) for a in answers])\n",
    "    \n",
    "    def get_clusters(self, words, n_cluster=3, n_components=2, eps=0.2, max_eps=0.1, method=\"kmeans\", seed=1):\n",
    "        word_vectors = np.array([self.embeddings.get(k) for k in words])\n",
    "        if method==\"kmeans\":\n",
    "            clustering = KMeans(n_clusters=n_cluster, random_state=seed).fit(word_vectors)\n",
    "        elif method==\"tsne-kmeans\":\n",
    "            word_vectors_embedded = TSNE(n_components=n_components).fit_transform(word_vectors)\n",
    "            clustering = KMeans(n_clusters=n_cluster, random_state=0).fit(word_vectors_embedded)\n",
    "        elif method==\"dbscan\":\n",
    "            clustering = DBSCAN(eps=0.2, min_samples=2, metric=\"cosine\").fit(word_vectors)\n",
    "        elif method==\"optics\":\n",
    "            clustering = OPTICS(min_samples=2, metric=\"cosine\", max_eps=max_eps).fit(word_vectors)\n",
    "        else:\n",
    "            raise Exception(\"Clustering method is unknown.\")\n",
    "\n",
    "        return(clustering.labels_)\n",
    "    \n",
    "    def candidates(self, size=5):\n",
    "        clusters = self.get_clusters(self.answers)\n",
    "        \n",
    "        for c in set(clusters):\n",
    "            this_cluster = np.array(self.answers)[clusters==c].tolist()\n",
    "            print(this_cluster)\n",
    "            best = sorted(self.embeddings.keys(), key=lambda w: -1 * self.goodness(w, this_cluster, self.bad))\n",
    "            res = [(str(i + 1), \"{0:.2f}\".format(self.minimax(w, this_cluster, self.bad)), w) \n",
    "                   for i, w in enumerate(sorted(best[:250], key=lambda w: -1 * self.minimax(w, this_cluster, self.bad))[:size])]\n",
    "            print([(\". \".join([c[0], c[2]]) + \" (\" + c[1] + \")\") for c in res])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "spymaster1 = SpyMaster(embeddings = emb_glove, game = game1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keg', 'shampoo', 'sloth', 'mole', 'comb']\n",
      "['1. dat (0.02)', '2. sys (0.02)', '3. snort (0.02)', '4. turd (0.02)', '5. freckles (0.01)']\n",
      "['hercules', 'hawaii', 'egypt']\n",
      "['1. mauritius (0.08)', '2. malta (0.07)', '3. dispatched (0.02)', '4. oman (0.01)', '5. fleet (0.01)']\n",
      "['leather']\n",
      "['1. boots (0.40)', '2. jackets (0.38)', '3. shoes (0.38)', '4. footwear (0.35)', '5. accessories (0.34)']\n"
     ]
    }
   ],
   "source": [
    "spymaster1.candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "spymaster2 = SpyMaster(embeddings = emb_bert, game = game1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shampoo', 'sloth']\n",
      "['1. malpractice (0.05)', '2. shakira (0.05)', '3. eminem (0.03)', '4. vacancies (0.02)', '5. cougar (0.02)']\n",
      "['hercules', 'mole', 'hawaii', 'comb', 'leather', 'egypt']\n",
      "['1. fbi (-0.04)', '2. mlb (-0.04)', '3. hull (-0.05)', '4. mali (-0.05)', '5. papua (-0.05)']\n",
      "['keg']\n",
      "['1. ketchup (0.09)', '2. blowjob (0.07)', '3. poop (0.07)', '4. doggy (0.07)', '5. bong (0.07)']\n"
     ]
    }
   ],
   "source": [
    "spymaster2.candidates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-nlp",
   "language": "python",
   "name": "py37-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
