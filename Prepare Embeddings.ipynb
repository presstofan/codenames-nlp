{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "embeddings_dict = {}\n",
    "with open(\"embeddings/glove/glove.6B.300d.txt\", 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Codenames word list\n",
    "codenames_df = pd.read_csv(\"word_list/codenames_word_list.csv\") \n",
    "codenames = pd.melt(codenames_df, id_vars=['ID', 'Version'], value_vars=['SideA', 'SideB'],\n",
    "        var_name='Side', value_name='Codename')['Codename'].tolist()\n",
    "codenames = [i.lower() for i in codenames] # convert to lowercase\n",
    "\n",
    "# remove two-word nouns\n",
    "one_word_idx = [' ' not in i for i in codenames]\n",
    "codenames = [i for (i, v) in zip(codenames, one_word_idx) if v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load common English words\n",
    "with open('word_list/google-10000-english.txt', 'r') as f:\n",
    "    english_common = f.read().splitlines()\n",
    "    \n",
    "# Remove one-letter words from the list\n",
    "# english_common = [i for i in english_common if len(i) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the common English words with the Codename words\n",
    "words_list = codenames + english_common\n",
    "words_list = list(dict.fromkeys(words_list)) # remove duplicates\n",
    "\n",
    "# Remove words from the combine word lists that does not appear in the embeddings\n",
    "embeddings_list = embeddings_dict.keys()\n",
    "not_in_embeddings = [x for x in words_list if x not in embeddings_list]\n",
    "words_list = [x for x in words_list if x not in not_in_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the embeddings dict with the words_list\n",
    "embeddings_lite_dict = {k: embeddings_dict[k] for k in words_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lite embeddings as pickle object\n",
    "pickle.dump( embeddings_lite_dict, open( \"glove_6B_300d_lite.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-nlp",
   "language": "python",
   "name": "py37-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
